# ğŸ‘¤ Catch Me If You Can: Alice Session Detection

> Binary classification project: identifying whether a user is **Alice** based on their internet session data.

---

## ğŸ§  Problem Statement

This is a **binary classification task** where each sample is a user session (a sequence of visited websites with timestamps).  
The goal is to **predict whether the session belongs to Alice**, a specific target user.

We use real session data from the [Kaggle competition](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2).

---

## ğŸ“Š Evaluation Metric

**ROC-AUC** (Receiver Operating Characteristic - Area Under Curve) is used because:

- it's threshold-independent
- handles class imbalance well
- measures the modelâ€™s ranking ability

---

## âš™ï¸ Project Structure
catch_me_alice/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ raw/ â† original train/test + site dictionary
â”œâ”€â”€ outputs/ â† saved models, vectorizer, top-10 sets
â”œâ”€â”€ src/ â† all logic for features, vectorizing, modeling
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ train.py â† trains model and saves components
â”‚ â””â”€â”€ predict.py â† loads model and predicts test probabilities
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md â† this file


---

## ğŸ—ï¸ Approach

1. **Feature Engineering**:
   - Number of sites in session
   - Number of unique sites
   - Session duration
   - Start hour, weekday, weekend indicator
   - Share of Aliceâ€™s top-10 websites
   - Cyclic time features (`sin/cos` for hour)

2. **Text Modeling**:
   - Websites in a session are treated as a string sequence
   - `CountVectorizer` used with 1â€“3 n-grams
   - Combined with engineered numerical features

3. **Modeling**:
   - Final model: **Logistic Regression** with regularization `C=1.0`
   - Compared with Random Forest, which underperforms due to sparse input

---

## ğŸš€ Results

| Model                 | ROC-AUC (Validation) |
|----------------------|----------------------|
| Logistic Regression  | **0.9775**           |
| Random Forest        | ~0.93                |

---

## ğŸ“¦ How to Run

### 1. Install requirements

'''
pip install -r requirements.txt
'''
### 2. Train the model

'''
python scripts/train.py
'''

This will:
- generate features
- train model + scaler + vectorizer
- save all to outputs/

### 3. Run prediction on test set

'''
python scripts/predict.py
''' 

This will:
- load the saved components
- apply them to the test sessions
- write submission.csv to outputs/

## ğŸ§© Dependencies

- pandas, numpy, scikit-learn
- joblib, scipy
- optionally: matplotlib/seaborn for EDA