{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Prediction \n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/safrin03/predictive-analytics-for-customer-churn-dataset/data\n",
    "\n",
    "About Dataset\n",
    "Context :\n",
    "\n",
    "This dataset is part of a data science project focused on customer churn prediction for a subscription-based service. Customer churn, the rate at which customers cancel their subscriptions, is a vital metric for businesses offering subscription services. Predictive analytics techniques are employed to anticipate which customers are likely to churn, enabling companies to take proactive measures for customer retention.\n",
    "\n",
    "Content :\n",
    "\n",
    "This dataset contains anonymized information about customer subscriptions and their interaction with the service. The data includes various features such as subscription type, payment method, viewing preferences, customer support interactions, and other relevant attributes. It consists of three files such as \"test.csv\", \"train.csv\", \"data_descriptions.csv\".\n",
    "\n",
    "Columns :\n",
    "\n",
    "- *CustomerID*: Unique identifier for each customer\n",
    "- *SubscriptionType*: Type of subscription plan chosen by the customer (e.g., Basic, Premium, Deluxe)\n",
    "- *PaymentMethod*: Method used for payment (e.g., Credit Card, Electronic Check, PayPal)\n",
    "- *PaperlessBilling*: Whether the customer uses paperless billing (Yes/No)\n",
    "- *ContentType*: Type of content accessed by the customer (e.g., Movies, TV Shows, Documentaries)\n",
    "- *MultiDeviceAccess*: Whether the customer has access on multiple devices (Yes/No)\n",
    "- *DeviceRegistered*: Device registered by the customer (e.g., Smartphone, Smart TV, Laptop)\n",
    "- *GenrePreference*: Genre preference of the customer (e.g., Action, Drama, Comedy)\n",
    "- *Gender*: Gender of the customer (Male/Female)\n",
    "- *ParentalControl*: Whether parental control is enabled (Yes/No)\n",
    "- *SubtitlesEnabled*: Whether subtitles are enabled (Yes/No)\n",
    "- *AccountAge*: Age of the customer's subscription account (in months)\n",
    "- *MonthlyCharges*: Monthly subscription charges\n",
    "- *TotalCharges*: Total charges incurred by the customer\n",
    "- *ViewingHoursPerWeek*: Average number of viewing hours per week\n",
    "- *SupportTicketsPerMonth*: Number of customer support tickets raised per month\n",
    "- *AverageViewingDuration*: Average duration of each viewing session\n",
    "- *ContentDownloadsPerMonth*: Number of content downloads per month\n",
    "- *UserRating*: Customer satisfaction rating (1 to 5)\n",
    "- *WatchlistSize*: Size of the customer's content watchlist\n",
    "\n",
    "Acknowledgments :\n",
    "The dataset used in this project is obtained from Data Science Challenge on Coursera and is used for educational and research purposes. Any resemblance to real persons or entities is purely coincidental.\n",
    "\n",
    "\n",
    "**The problem definition:**\n",
    "\n",
    "The goal of this project is to build a predictive model that identifies customers who are likely to churn (i.e., stop using the service). Using historical customer data — including demographics, subscription details, and usage behavior — we aim to classify whether a customer will churn or remain active.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBRFClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer,  recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('test.csv')\n",
    "df_train=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are no missing values\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check class balance\n",
    "df_train.groupby('Churn').CustomerID.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes are unbalanced. \n",
    "\n",
    "The strategy of metrics: Do not use accuracy, but F1-score (only for Class 1), ROC-AUC\n",
    "\n",
    "Balancing classes: Undersampling (delete the \"zero\" part of the users), oversampling (duplicate \"units\" or use SMOTE), or use models that take into account class weights (ex LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_col=[]\n",
    "for col  in df_train.columns:\n",
    "    if(df_train[col].dtypes in ('float64','int64')):\n",
    "        numeric_col.append(col)\n",
    "print(f\"Count of numeric columns in the datset - {len(numeric_col)}\")\n",
    "print(numeric_col)\n",
    "\n",
    "numeric_col.remove('Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find categorical  Columns\n",
    "categorial_col=[]\n",
    "for col  in df_train.columns:\n",
    "    if(df_train[col].dtypes=='object'):\n",
    "        categorial_col.append(col)\n",
    "print(f\"Count of categorical columns in the datset - {len(categorial_col)}\")\n",
    "print(categorial_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['CustomerID']\n",
    "del df_test['CustomerID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Features Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distribution(df, feature: str, title_feature: str = None, nbins: int = 60):\n",
    "\n",
    "    if title_feature is None:\n",
    "        title_feature = feature\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=(f\"Distribution of {title_feature} by Churn\", \n",
    "                        f\"Boxplot: {title_feature} by Churn\"),\n",
    "        shared_xaxes=False\n",
    "    )\n",
    "\n",
    "    hist_data = px.histogram(\n",
    "        df,\n",
    "        x=feature,\n",
    "        color=\"Churn\",\n",
    "        barmode=\"stack\",\n",
    "        nbins=nbins,\n",
    "        opacity=0.7\n",
    "    )\n",
    "\n",
    "    for trace in hist_data.data:\n",
    "        trace.showlegend = True\n",
    "        fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "    box_data = px.box(\n",
    "        df,\n",
    "        x=\"Churn\",\n",
    "        y=feature,\n",
    "        color=\"Churn\"\n",
    "    )\n",
    "\n",
    "    for trace in box_data.data:\n",
    "        trace.showlegend = False\n",
    "        fig.add_trace(trace, row=2, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        legend_title=\"Churn\",\n",
    "        xaxis=dict(title=title_feature),\n",
    "        xaxis2=dict(title=\"Churn\"),\n",
    "        yaxis=dict(title=\"Count Clients\"),\n",
    "        yaxis2=dict(title=title_feature),\n",
    "        title_text=f\"{title_feature} vs Churn — Histogram & Boxplot\"\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_col:\n",
    "    print(col)\n",
    "    print(df_train.groupby('Churn')[col].describe())\n",
    "    plot_feature_distribution(df_train, feature=col, title_feature=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we clearly see that: \n",
    "- Churned Users tend to have lover values for  Account Age, Total Charges, Content Downloads Per Month, Average Viewing Duration and Viewing Hours Per Week. These features are likely interrelated and potentially collinear.\n",
    "- Churned users also submit more support tickets, which may indicate a higher level of dissatisfaction, confusion, or unresolved technical issues — possibly contributing to their decision to leave.\n",
    "- Two features stand out as non-intuitive:\n",
    "    - Monthly Charges are higher among churned users, which might suggest pricing sensitivity or billing-related friction. This relationship needs further analysis\n",
    "    - Watchlist Size is also higher among churned users. A possible interpretation is that these users are interested in content but face e.g., technical issues, save items for later rather than watch them. A next step would be to explore the correlation between Watchlist Size and actual Viewing Time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorial Features Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_pie_by_churn(df, category_col: str, title: str = None):\n",
    "\n",
    "    if title is None:\n",
    "        title = f\"{category_col} Distribution by Churn\"\n",
    "\n",
    "    categories = df[category_col].dropna().unique().tolist()\n",
    "\n",
    "    default_colors = px.colors.qualitative.Plotly\n",
    "    color_map = {\n",
    "        cat: default_colors[i % len(default_colors)]\n",
    "        for i, cat in enumerate(categories)\n",
    "    }\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        specs=[[{'type': 'domain'}, {'type': 'domain'}]],\n",
    "        subplot_titles=[\n",
    "            f\"{category_col} (Churn = 0)\",\n",
    "            f\"{category_col} (Churn = 1)\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pie_0 = px.pie(\n",
    "        df[df['Churn'] == 0],\n",
    "        names=category_col,\n",
    "        hole=0.33,\n",
    "        category_orders={category_col: categories},\n",
    "        color=category_col,\n",
    "        color_discrete_map=color_map\n",
    "    )\n",
    "\n",
    "    pie_1 = px.pie(\n",
    "        df[df['Churn'] == 1],\n",
    "        names=category_col,\n",
    "        hole=0.33,\n",
    "        category_orders={category_col: categories},\n",
    "        color=category_col,\n",
    "        color_discrete_map=color_map\n",
    "    )\n",
    "\n",
    "    for trace in pie_0.data:\n",
    "        fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "    for trace in pie_1.data:\n",
    "        fig.add_trace(trace, row=1, col=2)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=title,\n",
    "        legend_title=category_col,\n",
    "        showlegend=True,\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_col=categorial_col[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorial_col:\n",
    "    plot_pie_by_churn(df_train, category_col=col, title=f\"{col} by Churn Statuses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are fewer clear distinctions in the categorical features between churned and non-churned users. However, a few patterns can be tentatively noted:\n",
    "\n",
    "- Churned users are more likely to have a Basic subscription, while non-churned users tend to subscribe to Premium plans, which may indicate a link between churn and perceived value or feature limitations.\n",
    "\n",
    "- There are also minor differences in the distribution of Payment Methods, but these patterns are less pronounced and would require statistical testing to validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df_train.select_dtypes(include=\"number\")\n",
    "corr = numeric_df.corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, square=True)\n",
    "plt.title(\"Correlation Matrix of Numeric Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = [\n",
    "    'AccountAge', 'MonthlyCharges', 'TotalCharges',\n",
    "    'ViewingHoursPerWeek', 'AverageViewingDuration',\n",
    "    'ContentDownloadsPerMonth', 'UserRating',\n",
    "    'SupportTicketsPerMonth', 'WatchlistSize'\n",
    "]\n",
    "\n",
    "X = df_train[features].copy()\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df['feature'] = features\n",
    "vif_df['VIF'] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "\n",
    "print(vif_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a high colinearity between AccountAge and TotalCharges. For linear models, we will remove the TotalCharges feature to avoid multicollinearity (this worsens the stability of the coefficients and confuses interpretation). Why TotalCharges? Usually, monetary metrics depend on many factors and are more difficult to interpret. For tree models (Decision Tree, Random Forest, XGBoost), you can leave both features. These models do not suffer from multicollenarity, they choose the desired feature themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: one look at outlier detection methods\n",
    "\n",
    "Let's take a short look at the methods of detecting outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Boxplot / Visual Inspection\n",
    "\n",
    "What it is - Visual method based on the IQR rule (Interquartile Range). Outliers are values outside the whiskers.\n",
    "\n",
    "Pros:\n",
    "- Quick and intuitive\n",
    "- Highlights extreme values clearly\n",
    "\n",
    "Cons:\n",
    "- Only works for 1D (single feature at a time)\n",
    "- Not scalable for high dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.plot(kind=\"box\", subplots=True, figsize=(12, 12), layout=(3, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  IQR \n",
    "\n",
    "- defines outliers as values beyond 1.5×IQR from Q1/Q3.\n",
    "\n",
    "Pros:\n",
    "- Very easy to implement\n",
    "- No assumptions about distribution\n",
    "\n",
    "Cons: \n",
    "- Ignores relationships between features\n",
    "- Not useful for multivariate anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_iqr_outliers(df, threshold=1.5):\n",
    "\n",
    "    numeric_cols = df[features]\n",
    "    outlier_counts = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower = Q1 - threshold * IQR\n",
    "        upper = Q3 + threshold * IQR\n",
    "\n",
    "        outliers = (df[col] < lower) | (df[col] > upper)\n",
    "        outlier_counts[col] = outliers.sum()\n",
    "\n",
    "    return pd.Series(outlier_counts).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_dict = count_iqr_outliers(df_train)\n",
    "outliers_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LocalOutlierFactor (LOF)\n",
    "\n",
    "Density-based algorithm. Compares local density of a point to its neighbors.\n",
    "\n",
    "Pros:\n",
    "- Captures local anomalies\n",
    "- No need to label data (unsupervised)\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Sensitive to n_neighbors parameter\n",
    "- It learns and evaluates only those points that were immediately given to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(n_neighbors=20)\n",
    "\n",
    "lof.fit_predict(df_train[numeric_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = lof.negative_outlier_factor_\n",
    "print(np.sort(df_scores)[0:6])\n",
    "\n",
    "scores = pd.DataFrame(np.sort(df_scores))\n",
    "plt.figure(figsize=(14, 10))\n",
    "scores.plot(stacked=True, xlim=[0, 16], style=\".-\", color=\"red\")\n",
    "plt.title(\"LocalOutlierFactor\", fontsize=24)\n",
    "plt.xlabel(\"Number of Neighbors\", fontsize=12)\n",
    "plt.ylabel(\"Scores\", fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid()\n",
    "plt.legend([\"LOF\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph helps you understand which number of neighbors is optimal - where the graph is already fairly stable (5-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest \n",
    "\n",
    "Tree-based algorithm that \"isolates\" anomalies quickly by random splits.\n",
    "\n",
    "Pros:\n",
    "- Scalable and fast\n",
    "- Works with mixed data\n",
    "- Can be used on new/unseen data\n",
    "\n",
    "Cons:\n",
    "- Can be unstable with small datasets\n",
    "- Randomness requires tuning / multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "df_train[\"iso_score\"] = iso.fit_predict(df_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = df_train[df_train[\"iso_score\"] == -1]\n",
    "inliers = df_train[df_train[\"iso_score\"] == 1]\n",
    "\n",
    "for col in numeric_col:\n",
    "    print(f\"{col}: outliers mean={outliers[col].mean():.2f}, inliers mean={inliers[col].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['iso_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= df_train.drop(columns='Churn')\n",
    "y_train=df_train['Churn']\n",
    "\n",
    "X_test = df_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose OneHotEncoder because it does not impose any artificial ordering between categories. Unlike LabelEncoder, which converts categories into integers (e.g., \"Basic\" → 0, \"Standard\" → 1, \"Premium\" → 2), OneHotEncoder treats each category as an independent binary feature.\n",
    "This avoids misleading the model into assuming a ranking where none exists — which is especially important for nominal variables such as subscription type, payment method, or content genre.\n",
    "\n",
    "We selected StandardScaler because it standardizes features by removing the mean and scaling to unit variance, which is optimal for most linear models, SVMs, and PCA.\n",
    "Compared to MinMaxScaler, StandardScaler is less sensitive to the presence of extreme values (though not fully robust) and does not squash data into a fixed 0–1 range, preserving variance.\n",
    "We did not use RobustScaler because our numerical features do not contain significant outliers that would distort mean-based scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = ['PaperlessBilling', 'MultiDeviceAccess', 'ParentalControl', 'SubtitlesEnabled']\n",
    "\n",
    "for col in binary_cols:\n",
    "    if X_train[col].dtype == 'object':\n",
    "        X_train[col] = X_train[col].map({'Yes': 1, 'No': 0})\n",
    "        X_test[col] = X_test[col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "X_train['Gender'] = X_train['Gender'].map({'Female': 1, 'Male': 0})\n",
    "X_test['Gender'] = X_test['Gender'].map({'Female': 1, 'Male': 0})\n",
    "\n",
    "\n",
    "scaled_features = [\n",
    "    'AccountAge', 'MonthlyCharges', 'TotalCharges', \n",
    "    'ViewingHoursPerWeek', 'AverageViewingDuration', \n",
    "    'ContentDownloadsPerMonth', 'UserRating',\n",
    "    'SupportTicketsPerMonth', 'WatchlistSize'\n",
    "]\n",
    "\n",
    "one_hot_encoding_cols = ['SubscriptionType', 'PaymentMethod', 'ContentType', 'DeviceRegistered', 'GenrePreference']\n",
    "\n",
    "\n",
    "all_cols = X_train.columns.tolist()\n",
    "\n",
    "other_features = [col for col in all_cols if col not in scaled_features + one_hot_encoding_cols]\n",
    "\n",
    "mapper = DataFrameMapper(\n",
    "\n",
    "    [([col], [SimpleImputer(strategy='mean'), StandardScaler()]) for col in scaled_features] +\n",
    "    [([col], [SimpleImputer(strategy='most_frequent'), OneHotEncoder(drop='first', sparse_output=False)]) for col in one_hot_encoding_cols] +\n",
    "    [([col], None) for col in other_features],\n",
    "\n",
    "    input_df=True, df_out=True\n",
    ")\n",
    "\n",
    "X_train_final = mapper.fit_transform(X_train)\n",
    "X_test_final = mapper.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('LogReg', LogisticRegression(max_iter=1000)),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('DTClass', DecisionTreeClassifier()),\n",
    "    ('RFClass', RandomForestClassifier()),\n",
    "    ('GBM', GradientBoostingClassifier()),\n",
    "    (\"XGBoost\", XGBRFClassifier()),\n",
    "    (\"LightGBM\", LGBMClassifier())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "for name, model in models:\n",
    "    acc = cross_validate(model, X_train_final, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Recall:\", round(acc[\"test_recall\"].mean(), 4))\n",
    "    print(\"F1:\", round(acc[\"test_f1\"].mean(), 4))\n",
    "    print(\"ROC AUC:\", round(acc[\"test_roc_auc\"].mean(), 4))\n",
    "    print(f\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the goal is to catch as many CHURN (1s) as possible (high Recall):\n",
    "Best result: DecisionTree (DT) — Recall = 0.30 -> but at the same time, the terrible AUC model stupidly \"predicts 1 for everyone in a row.\"\n",
    "\n",
    "If you need a quality balance (F1 + AUC): \n",
    "\n",
    "- LogisticRegression is the most balanced: F1 = 0.1961, ROC AUC = 0.75\n",
    "\n",
    "- LightGBM and GBM are close in AUC, but Recall is lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - SMOTE\n",
    "\n",
    "SMOTE (Synthetic Minority Oversampling Technique) is a smart way to \"add\" more than 1 without copying them, but creating new similar ones.\n",
    "It is used when it is necessary to improve recall or F1 in a minority class, especially when there is an imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "            }\n",
    "\n",
    "models = [\n",
    "    (\"LogReg\", LogisticRegression(class_weight=None, max_iter=1000, random_state=42)),\n",
    "    (\"RandomForest\", RandomForestClassifier(class_weight=None, n_estimators=100, random_state=42)),\n",
    "    (\"DecisionTree\", DecisionTreeClassifier(class_weight=None, random_state=42))\n",
    "]\n",
    "\n",
    "\n",
    "for name, model in models:\n",
    "    pipe = Pipeline([\n",
    "        ('smote', smote),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    acc = cross_validate(pipe, X_train_final, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Recall:\", round(acc[\"test_recall\"].mean(), 4))\n",
    "    print(\"F1:\", round(acc[\"test_f1\"].mean(), 4))\n",
    "    print(\"ROC AUC:\", round(acc[\"test_roc_auc\"].mean(), 4))\n",
    "    print(f\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - class_weight='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "models = [\n",
    "    (\"LogReg_balanced\", LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)),\n",
    "    (\"RandomForest_balanced\", RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)),\n",
    "     (\"DecisionTree_balanced\", DecisionTreeClassifier(class_weight='balanced', random_state=42))\n",
    "\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    acc = cross_validate(model, X_train_final, y_train, cv=cv, scoring=scoring)\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Recall:\", round(acc[\"test_recall\"].mean(), 4))\n",
    "    print(\"F1:\", round(acc[\"test_f1\"].mean(), 4))\n",
    "    print(\"ROC AUC:\", round(acc[\"test_roc_auc\"].mean(), 4))\n",
    "    print(f\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train_final, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "model.fit(X_tr, y_tr)\n",
    "\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_proba = model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred, digits=4))\n",
    "\n",
    "\n",
    "print(\"ROC AUC:\", round(roc_auc_score(y_val, y_val_proba), 4))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "y_val_pred_custom = (y_val_proba >= threshold).astype(int)\n",
    "\n",
    "print(\"Classification Report (threshold = 0.3):\")\n",
    "print(classification_report(y_val, y_val_pred_custom, digits=4))\n",
    "\n",
    "print(\"ROC AUC:\", round(roc_auc_score(y_val, y_val_pred_custom), 4))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We experimented with lowering the classification threshold to 0.3 in order to capture more positive cases (churned customers). While this significantly increased recall (up to ~92%), it also caused a sharp drop in precision (down to ~24%) and overall accuracy.\n",
    "\n",
    "This means that although we correctly identified almost all churners, the model also falsely labeled a very large number of non-churners as churners. In practical terms, this could lead to wasting resources on users who are not actually at risk, which may not be sustainable in a real-world scenario.\n",
    "\n",
    "Therefore, a threshold of 0.3 does not provide a good balance between recall and precision, and we recommend sticking with the default threshold of 0.5 or finding an optimized value based on business constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result:\n",
    "- LogisticRegression\n",
    "- class_weight='balanced' (threshold = 0.5) \n",
    "- F1 = 0.1961, ROC-AUC = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Logistic Regression Suitable for Predicting Churn?\n",
    "\n",
    "Technically, yes. Logistic regression is a valid choice for predicting whether a customer will churn (binary outcome: 1 or 0). However, in our case, we have more than just the churn indicator — we also know how long a customer stays before leaving.\n",
    "\n",
    "This means we are dealing with two variables:\n",
    "\n",
    "- A binary variable: whether the customer churned (1/0),\n",
    "- A continuous variable: the time until churn.\n",
    "\n",
    "Generalized Linear Models (GLM)\n",
    "GLM is a general modeling framework defined by the equation:\n",
    "\n",
    "$$\n",
    "g(\\mathbb{E}[Y]) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "- Y  - the target variable,\n",
    "- 𝑔 - the link function,\n",
    "- 𝛽 - are the model coefficients.\n",
    "\n",
    "Logistic regression is just a special case of GLM, where the link function is the logit, and the target variable \n",
    "\n",
    "Time-to-Event Modeling and the Weibull Distribution\n",
    "When we model time until an event (like churn), we enter the domain of survival regression. A common choice for modeling such durations is the Weibull distribution.\n",
    "\n",
    "The Weibull distribution is flexible and defined by two parameters:\n",
    "\n",
    "- 𝛼 (scale) — controls the spread of the distribution,\n",
    "- 𝜌 (shape) — controls the hazard behavior over time.\n",
    "\n",
    "Different values of 𝜌 allow the distribution to model increasing, decreasing, or constant risk over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import weibull_min\n",
    "\n",
    "x_weibull = np.linspace(0, 5, 500)\n",
    "shapes = [0.5, 1, 1.5, 2, 5]\n",
    "plt.figure(figsize=(6, 4))\n",
    "for shape in shapes:\n",
    "    y_weibull = weibull_min.pdf(x_weibull, c=shape)\n",
    "    plt.plot(x_weibull, y_weibull, label=f\"rho = {shape}\")\n",
    "\n",
    "plt.title(\"Weibull Distributions with Different Shape Parameters\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lifelines as lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = df_train.loc[:, ['Churn', 'AccountAge', 'SubtitlesEnabled', 'ParentalControl',\n",
    "                          'MonthlyCharges', 'PaperlessBilling',\n",
    "                          'PaymentMethod','SubscriptionType',\n",
    "                         'ViewingHoursPerWeek','UserRating',\n",
    "                         'SupportTicketsPerMonth',\n",
    "                         'ContentType', 'MultiDeviceAccess','DeviceRegistered',\n",
    "                         'AverageViewingDuration', 'ContentDownloadsPerMonth',\n",
    "                         'GenrePreference','WatchlistSize'\n",
    "                ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(churn.AccountAge, kde = False)\n",
    "plt.xlabel('Number of months')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Time of customers in the company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv = lf.WeibullAFTFitter()\n",
    "\n",
    "surv.fit(df = churn, duration_col = 'AccountAge', event_col = 'Churn', \\\n",
    "         formula = 'C(SubtitlesEnabled) + C(ParentalControl) + MonthlyCharges + C(PaperlessBilling)\\\n",
    "         +C(PaymentMethod) + C(SubscriptionType) + ViewingHoursPerWeek + UserRating + SupportTicketsPerMonth + \\\n",
    "         C(ContentType) + C(MultiDeviceAccess)+ C(DeviceRegistered)+\\\n",
    "            AverageViewingDuration + ContentDownloadsPerMonth + C(GenrePreference) + WatchlistSize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = surv.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary = surv.summary.reset_index()\n",
    "summary = summary[summary[\"p\"] < 0.05]  \n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.barplot(\n",
    "    data=summary,\n",
    "    x=\"coef\",\n",
    "    y=\"covariate\",  \n",
    "    color=\"steelblue\",\n",
    "    errorbar=None\n",
    ")\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.title(\"Significent coefs\")\n",
    "plt.xlabel(\"coef\")\n",
    "plt.ylabel(\"factor\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factors that increase account longevity :\n",
    " - Premium Subscription  -> Increases account lifetime by ~17% \n",
    " - Credit Card Payment ->  Associated with ~9% longer account life — possibly indicating more committed users\n",
    "- Content Type  TV Shows and Movies ->  6–8% longer lifetime\n",
    "- Content Downloads per Month -> Slight but significant positive effect on retention.\n",
    "\n",
    "Factors that shorten account lifetime:\n",
    "- Support Tickets per Month (to ~5%)\n",
    "- Genre Preferences (Comedy, Sci-Fi, Fantasy, Drama) -> negatively associated with account longevity (up to 12% shorter time)\n",
    "- Monthly Charges -> Higher charges slightly increase churn risk.\n",
    "- Watchlist Size: -> A larger watchlist without corresponding viewing activity may indicate disengagement.\n",
    "\n",
    "To conclude, users with a premium subscription who frequently watch content and use a credit card to pay stay longer. The more problems (tickets) a user has or he prefers comedy/fiction, the higher the risk of churn. Increased activity (views and downloads) lengthens the life span, while expensive pricing and poor user experience shorten it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
